# Weighted Model-based Reinforcement Learning
Source codes for the experiments in [A Unified Framework for Alternating Offline Model Training and Policy Learning]( ).

## Installation
1. Install basic packages, using *e.g.*,
```angular2html
conda create -n wmbrl python=3.8.5
conda activate wmbrl
pip install numpy matplotlib seaborn gym==0.17.0 torch==1.10.1 cudatoolkit==11.1.74
```
and adding other possible dependencies.
2. Install [MuJoCo](http://www.mujoco.org/) and [mujoco-py](https://github.com/openai/mujoco-py).
3. Install [D4RL](https://github.com/rail-berkeley/d4rl).

## Offline RL Experiment

### Main Method
The run files to run the experiments are generated by the `submit_jobs_server_gan.py` file.
An example use of this file is 
```angular2html
python submit_jobs_server_gan.py
```
Flags can be provided to the `python` command.
Please take a look at this file for available flags.

The location of the generated run files will be printed out.

### Evaluation
The run files will generate a folder for each `(dataset, seed)` pair. 
Within a such folder, the file `eval_norm.npy` stores the normalized scores and `eval.npy` records the unnormalized scores. 
The normalized scores are calculated by the D4RL package.

### Algorithmic Variants
Below lists the commands for the variants used in our ablation study.

* No weighted model retraining (train model only once in the beginning using MLE)
```angular2html
python submit_jobs_server_gan.py --model_retrain_period=1000
```
* Use VPM to train MIW model
```angular2html
python submit_jobs_server_gan.py --dr_method="VPM" --weight_output_clipping="True"
```
* Use GenDICE to train MIW model
```angular2html
python submit_jobs_server_gan.py --dr_method="GenDICE" --weight_output_clipping="True"
```
* Use DualDICE to train MIW model
```angular2html
python submit_jobs_server_gan.py --dr_method="DualDICE" --weight_output_clipping="True"
```
* Use weighted policy-regularizer
```angular2html
python submit_jobs_server_gan.py --weighted_policy_training='True'
```
* KL-Dual + weighted policy-regularizer
```angular2html
python submit_jobs_server_gan.py --weighted_policy_training='True' --use_kl_dual='True' --use_weight_wpr='True'
```
* KL-Dual + No-weighted policy-regularizer
```angular2html
python submit_jobs_server_gan.py --weighted_policy_training='True' --use_kl_dual='True' --use_weight_wpr='False'
```
* Gaussian policy + JSD for policy training
```angular2html
python submit_jobs_server_gan.py --use_gaussian_policy='True'
```
* No regularization in policy training
```angular2html
python submit_jobs_server_gan.py --remove_reg='True'
```
* No model-rollout data (`real_data_pct=1`)
```angular2html
python submit_jobs_server_gan.py --real_data_pct=1.
```
* Use reward function as the test function in training the MIW
```angular2html
python submit_jobs_server_gan.py --use_reward_test_func='True'
```
* Use Value-function as discriminator to train model
```angular2html
python submit_jobs_server_gan.py --q_dis_model='True'
```

## License
MIT License.


